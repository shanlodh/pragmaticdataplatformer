Whilst everyone's looking at ChatGPT I am trying to think beyond it and understand the broader landscape that is evolving rapidly following this remarkable innovation. Here's five that are resonating right now: 

- **Is Anyscale the new Databricks:** ["... … OpenAI is very secretive"](https://thenewstack.io/how-ray-a-distributed-ai-framework-helps-power-chatgpt/), chuckles Ion Stoica, co-founder [Databricks](https://www.databricks.com/), [Anyscale](https://www.anyscale.com/) and [CS Professor at UC, Berkeley](https://people.eecs.berkeley.edu/~istoica/). One technology OpenAI does acknowledges using however is from Anyscale (see image below) viz. [the Python package Ray](https://pypi.org/project/ray/). Think of Ray being for GPU's what Spark was for CPU's, hence this bullet title. The other significant innovation from Ray is its adoption of the [Actor pattern](https://docs.ray.io/en/latest/ray-core/actors.html) which is a stateful worker for distributed processing that has much wider applications across data platforms. Certainly a company to watch, couple podcasts ([March, 2022](https://www.pythonpodcast.com/anyscale-machine-learning-applications-episode-355) and [April, 2020](https://www.pythonpodcast.com/ray-distributed-computing-episode-258)) with [Anyscale co-founder Robert Nishihara](http://www.robertnishihara.com/) provide more in-depth references to Ray 

- **Get your chips:** LLMs, diffusion, RL all draw heavily on GPU's and [Nvidia is seen as one of the main beneficiaries](https://www.bloomberg.com/news/articles/2023-01-23/nvidia-nvda-is-wall-street-s-top-stock-pick-for-chatgpt-mania) in this space. With reports of ['Code Red' at Google from ChatGPT](https://www.cnet.com/tech/services-and-software/chatgpt-caused-code-red-at-google-report-says/) also wonder if GOOG wants to start making the [TPU](https://cloud.google.com/tpu/docs/tpus) more multi-cloud GA and less GCP focused, specially on the back of the [CHIPS Act](https://www.nist.gov/semiconductors/chips-act)

- **From silent era to talkies:** If you have watched [Babylon](https://www.imdb.com/title/tt10640346/) recently, current AI landscape, despite hype, feels like silent-era Hollywood. We have images ([DALL∙E](https://openai.com/dall-e-2/)) and text ([ChatGPT](https://openai.com/blog/chatgpt/)) but they are not synchronised. Instead we have a leader-follower pattern (input text, create image or run image, create sub-titles). The 'talkie' era of AI will see multiple generative models producing synchronised tokens (a la motion picture lip-sync). This requires a fundamental new type of cross-entropy going beyond existing [Shannon/Kullback-Leibler](https://en.wikipedia.org/wiki/Entropy_(information_theory)) paradigm that models different distributions over the same random variable. We need new types of loss functions that cross-evaluate real-time tokens across text and image space (if you are aware of such developments do mention in comments)

- **Software eats world, AI eats software:** "Software is eating the world" feels so BC (Before ChatGPT), surely AI is now eating software? Though ChatGPT serves (reasonably) well-formed code in various languages, the underlying engine where this magic happens is actually the [OpenAI Codex](https://openai.com/blog/openai-codex/) system. [GitHub Copilot](https://github.com/features/copilot) also uses OpenAI Codex under the hood. One significant pure play in this space is the new $550m  AI-dedicated fund from [Radical Venture, Toronto](https://radical.vc/) investing solely in AI start ups. The [fund's investors](https://www.ft.com/content/118e353d-94b8-4025-a76c-bdf206fcfcb0) include [Fei-Fei Li](https://en.wikipedia.org/wiki/Fei-Fei_Li) (ImageNet) and [Geoffrey Hinton](https://en.wikipedia.org/wiki/Geoffrey_Hinton) (neural networks), expect to see significant more upcoming investments in the pure AI / generative learning / GPU / TPU space 

- **On AI ethics, trust and security:** As a Data Platform practitioner accuracy, fairness, explicability of these AI models and the environmental considerations of training them are things I care deeply about. AI is amazing and can unlock humanity's potential tremendously. But unless  industry and regulators work together from onset we will repeat several adverse outcomes from social media and crypto. One of the most thoughtful treatment of these topics I have read is ["Challenges in Deploying Machine Learning: a Survey of Case Studies"](https://arxiv.org/abs/2011.09926) by three researchers at Cambridge, UK. It's sections on ethics, trust, security of ML/AI and how to think about tools and holistic approaches to address these should be mandatory read as we embark upon the next stage of our civilisation's journey  

Views strictly personal


<p align="center">
  <img src="https://github.com/shanlodh/pragmaticdataplatformer/blob/main/02_BeyondChatGPT/Images/RayChatGPT.jpg" />
</p>