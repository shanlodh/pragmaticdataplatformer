# Lean Data Platform

During 2022 the game has evolved for data platform teams. As we face the first stagflation (slowing growth, rising inflation) shock since the widespread migration of data platforms to public cloud, it is no longer enough to be able to just move data around. Data platform teams need to do this with the highest possible efficiencies, lowest costs and also be prepared to share our knowledge and understaing of public cloud providers with the wider organisation to optimise costs and drive business value

Here are five suggestions towards a lean data platform (examples use Azure API's, similar services exist on other providers): 

- **Modernise your apps:** to take full advantge of public cloud, companies must go serverless, scale horizontally and become event-driven as much as possible. Lift and shift can be an interim step but continuing to write apps the same way as in DC world literally leaves money on the table. For example, see [the Forrester study on 228% RoI from PaaS oriented app modernisation](https://azure.microsoft.com/en-us/blog/forrester-study-finds-228-percent-roi-when-modernizing-applications-on-azure-paas/) or listen to [The Azure Podcast, Episode 444](https://azpodcast.azurewebsites.net/post/Episode-444-Azure-Innovations), where around 8 mins in Microsoft CSA Mark Eisenberg makes this great point about *"... going into cloud to save money alone and not changing your architecture is a non-starter, so costs are getting out of control ..."* 

- **Instrument and observe:** while observability gets increasing community mentions, there can be no observability without instrumentation. And observability should be not just for data pipelines or data quality but for the overall data platform itself. Here the benefit of public cloud is that large providers offer comprehensive OOB instrumentation and if you need bespoke ones you can use context managers like [Azure Resource Manager](https://learn.microsoft.com/en-us/azure/azure-resource-manager/management/overview) combined with the observability platform of [Azure Monitor](https://learn.microsoft.com/en-us/azure/azure-monitor/overview) to get any level of details into your [Azure Log Analytics Workspace](https://learn.microsoft.com/en-us/azure/azure-monitor/logs/log-analytics-workspace-overview) and then run relevant [KQL](https://learn.microsoft.com/en-us/azure/data-explorer/kusto/query/) queries over the logs 

- **Make cost management a team sport:** cost management API such as [Azure/Microsoft Cost Management](https://learn.microsoft.com/en-us/rest/api/cost-management/) (also connects to AWS) will be our new best friend going into 2023. Know this API thoroughly, it also has a [Python SDK](https://learn.microsoft.com/en-us/python/api/overview/azure/cost-management?view=azure-python) for a programmatic approach to stay on top of costs at any level of detail. Depending on your company's charge back policies, develop a consistent [tagging policy](https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-best-practices/naming-and-tagging) so that each functional area is fully aware of their public cloud costs. You can also use the [Azure Cost Management connector in Power BI Desktop](https://learn.microsoft.com/en-us/power-bi/connect-data/desktop-connect-azure-cost-management) to share real-time trends in public cloud costs throughout the organisation, thus making cost management a true team sport  

- **Seek professional help:** as your data platform footprint on the public cloud  grows, you may find certain services contributing to a larger share of costs. Beyond resources provided by the cloud providers themselves like the [Azure Well Architected Framework](https://learn.microsoft.com/en-us/azure/architecture/framework/) and your own analysis, at a certain level of costs it could become cost-effective to seek specialised help for specific parts of your stack. E.g., for Snowflake costs consider [Bluesky](https://www.getbluesky.io/) or for Postgres and MySQL look at companies like [OtterTune](https://ottertune.com/) for AI powered database optimisations to drive costs efficiencies 

- **Check tax laws for public cloud costs optimisations:** depending on your company's jurisdiction, work with finance, accounting and legal teams to explore if any public cloud data platform build costs are eligible for capitalisation and depreciation treatments. There may be other options in your particular jurisdiction, the general principle being that lean data platform teams are always business first and should instigate, participate in these conversations with relevant colleagues to drive business value 

***Views strictly personal***