Whilst everyone's looking at ChatGPT I also want to go beyond it and try and understand the broader landscape that is evolving rapidly from this remarkable innovation

Following views strictly personal, references through link at bottom: 

- **Is Anyscale the new Databricks:** ["... … OpenAI is very secretive"](https://www.businessinsider.com/openai-chatgpt-trained-on-anyscale-ray-generative-lifelike-ai-models-2022-12?r=US&IR=T), says Ion Stoica, co-founder [Databricks](https://www.databricks.com/), [Anyscale](https://www.anyscale.com/) and [CS Professor at UC, Berkeley]((https://people.eecs.berkeley.edu/~istoica/)). One technology OpenAI does acknowledges using however is from Anyscale (see image below) viz. [Python package Ray](https://pypi.org/project/ray/). Think of Ray being for GPU's what Spark was for CPU's, hence the bullet title. The other significant innovation from Ray is its adoption of the [Actor pattern](https://docs.ray.io/en/latest/ray-core/actors.html) which is a stateful worker for distributed processing that has much wider applications across data platforms. Certainly a company to watch, couple podcasts ([March, 2022](https://www.pythonpodcast.com/anyscale-machine-learning-applications-episode-355) and [April, 2020](https://www.pythonpodcast.com/ray-distributed-computing-episode-258)) with [Anyscale co-founder Robert Nishihara](http://www.robertnishihara.com/) provide more in-depth references to Ray 

- **Get your chips:** LLMs, diffusion, RL all draw heavily on GPU's and [Nvidia is seen as one of the main beneficiaries](https://www.bloomberg.com/news/articles/2023-01-23/nvidia-nvda-is-wall-street-s-top-stock-pick-for-chatgpt-mania) in this space. With reports of ['Code Red' at Google from ChatGPT](https://www.cnet.com/tech/services-and-software/chatgpt-caused-code-red-at-google-report-says/) also wonder if GOOG wants to start making the [TPU](https://cloud.google.com/tpu/docs/tpus) more multi-cloud GA and less GCP focused, specially on the back of the [CHIPS Act](https://www.nist.gov/semiconductors/chips-act)

- **From silent era to talkies:** If you have watched [Babylon](https://www.imdb.com/title/tt10640346/) recently, current AI landscape, despite hype, feels like silent-era Hollywood. We have images ([DALL∙E](https://openai.com/dall-e-2/)) and text [[ChatGPT](https://openai.com/blog/chatgpt/)] but not fully synchronised. They follow a leader-follower pattern (input text, create image or run image, create sub-titles). The 'talkie' era of AI should see multiple generative models producing synchronised tokens (a la motion picture lip-sync). This requires a fundamental new type of cross-entropy going beyond existing [Shannon/Kullback-Leibler](https://en.wikipedia.org/wiki/Entropy_(information_theory)) paradigm that models different distributions over the same random variable. We need new types of loss functions that cross-evaluate real-time tokens across text and image space (if you are aware of such developments do mention in comments)

- **Software eats world, AI eats software:** "Software is eating the world" is so BC (before ChatGPT), surely AI is now eating software? Though ChatGPT serves (reasonably) well-formed code in various languages, the underlying engine where this magic happens is actually the [OpenAI Codex](https://openai.com/blog/openai-codex/) system. [GitHub Copilot](https://github.com/features/copilot) also uses OpenAI Codex under the hood. One of the largest pure plays in this space is the new [$550m  AI-dedicated fund from Radical Venture, Toronto for investing in AI start ups](https://www.ft.com/content/118e353d-94b8-4025-a76c-bdf206fcfcb0). Radical Venture investors include [Fei-Fei Li](https://en.wikipedia.org/wiki/Fei-Fei_Li) (ImageNet) and [Geoffrey Hinton](https://en.wikipedia.org/wiki/Geoffrey_Hinton) (neural networks), expect to see significant more investments in the pure AI /generative learning / GPU / TPU space 

- **On AI ethics, trust and security:** As a Data Platform practitioner accuracy, fairness, explicability of these AI models and the environmental considerations of training them are things I care deeply about. True, the new tech is amazing and can unlock humanity's potential in ways we haven't even considered. But unless AI and regulators, watchdogs work together from onset we will repeat several adverse outcomes of social media and crypto. One of the most thoughtful treatment of these topics that I have come across is in ["Challenges in Deploying Machine Learning: a Survey of Case Studies"](https://arxiv.org/abs/2011.09926) by three researchers at Cambridge, UK. It's sections on ethics, trust, security of ML/AI and how to think about tools and other holistic approaches to address these should be mandatory read as we embark upon the next stage of our civilisation's journey  